Morphology studies the rules that govern the ways that the morphemes
of a language may be put together in meaningful ways. For example,
inflecting the word \textit{walk} to form its present participle form
\textit{walking} indicates that the action is ongoing in the sentence
\textit{I am walking}. In many languages, morphology can play an even
larger role, and may encode many inflectional categories such as
tense, aspect, mood, number, gender, or case. The syntax and semantics
of a sentence are highly dependent on this information, and it is
therefore crucial that natural language processing systems use
morphological analyses.

Despite the importance of morphology, many state of the art language
technologies such as machine translation, speech recognition, and
question answering do not properly parse lexical information. This is
in part due to the amount of resources that are necessary to build
proper morphological analyzers. Typical morphological analyzers use
hand-built, finite-state rules to segment words and label each
segmentation with its syntactic purpose. For example, the
\textit{-ing} suffix typically marks the verb as a present participle,
which together with the auxiliary verb \textit{to be} forms the
continuous tense. Compiling such a collection of rules and efficiently
implementing them as a software tool requires expertise in both
linguistics and computer science. Furthermore, such tools must be
rebuilt for each language, which, depending on the availability of
existing corpora and linguistic resources, can be both costly and time
consuming.

There has recently been much interest in automating the process of
morphological analysis using statistical machine learning
algorithms. Automating such systems would address a number of
challenges in natural language processing. First, being able to
automatically compile rich linguistic information for resource-scarce
languages would help to both preserve and better understand languages
with relatively few speakers (compared to the billions that speak
English, for example). Second, automatically creating such resources
could potentially provide an easy way to improve existing language
technologies. For example, \cite{stallard2012} show that an Arabic
machine translation system using an unsupervised morphological
analyzer rivals a system using a supervised analyzer. Finally, such
models may offer scientific insight and could be used to test
linguistic hypotheses. If a morphological theory is implemented as a
model, and the model learns accurate segmentations of a language's
words, then it may demonstrate that the theory has captured an
important principle of the language's morphology.

Bayesian nonparametric models have recently been applied to the
problem of unsupervised morphology induction and have demonstrated
promising results \cite{goldwater2011,dreyer2011,lee2011}. In
particular, the Dirichlet process (DP) and Pitman-Yor process (PYP)
can be used as priors over discrete, long-tailed distributions, which
are characteristic of natural language data
\cite{goldwater2011}. Furthermore, the DP and PYP generate
distributions with potentially unbounded support, making them natural
formalisms for modeling languages with productive morphology
(i.e. there is always a small probability that one will observe a
completely novel word type).

There is no known, closed-form expression for the distributions
described by the DP and PYP. There are, however, several algorithms
for sampling from the distributions, which can be used for inference,
but require computationally expensive Monte Carlo Markov Chain
procedures. While Bayesian nonparametric models of morphology are a
promising direction, algorithms for learning and using such models may
be prohibitively expensive.

It is especially important for morphological analyzers to be
relatively efficient because they are often used as preprocessing
procedures for tools that perform syntactic and semantic analysis
further down the NLP ``pipeline''. In other fields such as information
retrieval, crude morphological analysis known as \textit{stemming} is
used to reduce the dimensionality of documents that have been encoded
as a bag of words. Proper morphological analysis could help to improve
this dimensionality reduction, but Bayesian nonparametric models would
not scale well when processing the massive amounts of data indexed by
modern information retrieval engines.

In this work, we address the issue of efficiency in Bayesian
nonparametric models of morphology. Specifically, we formulate and
implement a model that extends the seminal work of
\cite{goldwater2011}. Our new model is inspired by a recent
reparameterization of DP mixture models that allows the Chinese
Restaurant Process (CRP) to be split among several compute nodes in
order to speed up inference \cite{williamson2013}. In Section
\ref{sec:existing-models}, we review the morphological model that we
have extended and discuss some of the linguistic assumptions encoded
in the model. With a thorough understanding of the baseline in place,
we discuss the DP mixture model in Section \ref{sec:dpmm} and review
the recent work on parallelizing inference. Additionally, we draw
connections between the baseline model in Section
\ref{sec:existing-models} and DP mixture models, which motivates the
design of our parallelized model. In Section
\ref{sec:parallel-goldwater} we introduce our primary contribution and
discuss the decisions made when designing and implementing our
proposed model. Section \ref{sec:evaluation} describes the datasets on
which we evaluated our model, and presents results demonstrating that
our parallel model successfully recovers the same analyses as the
baseline and significantly improves the speed of inference when
compared against a baseline serial model.
